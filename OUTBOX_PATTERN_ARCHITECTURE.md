# Outbox Pattern vá»›i Redis Stream - Kiáº¿n trÃºc vÃ  CÃ¡ch hoáº¡t Ä‘á»™ng

## ğŸ“‹ Tá»•ng quan

Outbox Pattern lÃ  má»™t pattern Ä‘á»ƒ Ä‘áº£m báº£o **reliable event publishing** trong microservices architecture. Pattern nÃ y Ä‘áº£m báº£o ráº±ng:
- Events Ä‘Æ°á»£c lÆ°u trong database **cÃ¹ng transaction** vá»›i domain changes
- Events Ä‘Æ°á»£c publish má»™t cÃ¡ch **Ä‘Ã¡ng tin cáº­y** vÃ  **khÃ´ng bá»‹ máº¥t**
- CÃ³ kháº£ nÄƒng **retry** khi publish tháº¥t báº¡i

---

## ğŸ—ï¸ Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Service Layer  â”‚
â”‚  (JobService)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 1. Save Entity + OutboxEvent (same transaction)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL Database    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  jobs              â”‚  â”‚
â”‚  â”‚  outbox_events     â”‚â—„â”€â”¼â”€â”€ Status: PENDING
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 2. Scheduled Processor (every 5 seconds)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OutboxEventProcessor    â”‚
â”‚  - Reads PENDING events  â”‚
â”‚  - Publishes to Redis    â”‚
â”‚  - Updates status        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ 3. Publish to Stream
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Redis Stream         â”‚
â”‚  Stream: outbox:events    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Message 1: CREATED   â”‚ â”‚
â”‚  â”‚ Message 2: UPDATED   â”‚ â”‚
â”‚  â”‚ Message 3: DELETED  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ 4. Consumer reads from stream
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python Service         â”‚
â”‚  - Consumes messages     â”‚
â”‚  - Syncs to Milvus       â”‚
â”‚  - Acknowledges messages â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Luá»“ng hoáº¡t Ä‘á»™ng chi tiáº¿t

### **BÆ°á»›c 1: Táº¡o Event trong Transaction**

Khi service táº¡o/cáº­p nháº­t/xÃ³a entity, nÃ³ lÆ°u cáº£ entity VÃ€ outbox event trong **cÃ¹ng má»™t transaction**:

```java
@Transactional
public JobResponse createJob(Account account, CreateJobRequest request) {
    // 1. Save domain entity
    Job job = jobRepository.save(new Job(...));
    
    // 2. Convert to DTO
    JobResponse jobResponse = jobMapper.toResponse(job);
    
    // 3. Save outbox event (same transaction!)
    String payload = objectMapper.writeValueAsString(jobResponse);
    outboxEventService.saveOutboxEvent(
        "JOB",           // aggregateType
        job.getId(),     // aggregateId
        "CREATED",       // eventType
        payload          // JSON string
    );
    
    // âœ… Náº¿u transaction commit â†’ cáº£ job vÃ  outbox event Ä‘á»u Ä‘Æ°á»£c lÆ°u
    // âŒ Náº¿u transaction rollback â†’ cáº£ job vÃ  outbox event Ä‘á»u bá»‹ há»§y
    return jobResponse;
}
```

**Database State sau BÆ°á»›c 1:**
```
outbox_events table:
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ id â”‚aggregateType â”‚aggregateId  â”‚eventType â”‚  status  â”‚attempts â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚123 â”‚ "JOB"        â”‚     456     â”‚ "CREATED"â”‚ "PENDING"â”‚   0     â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **BÆ°á»›c 2: Background Processor**

`OutboxEventProcessor` cháº¡y **má»—i 5 giÃ¢y** Ä‘á»ƒ:
1. TÃ¬m táº¥t cáº£ events cÃ³ status = `PENDING`
2. Publish tá»«ng event vÃ o Redis Stream
3. Update status thÃ nh `SENT` (náº¿u thÃ nh cÃ´ng) hoáº·c `FAILED` (náº¿u tháº¥t báº¡i)

```java
@Scheduled(fixedDelay = 5000, initialDelay = 10000)
@Transactional
public void processPendingEvents() {
    // 1. Query PENDING events (with pessimistic lock)
    List<OutboxEvent> pendingEvents = 
        outboxEventRepository.findPendingEvents(OutboxStatus.PENDING);
    
    // 2. Process each event
    for (OutboxEvent event : pendingEvents) {
        boolean success = redisStreamPublisher.publishToStream(event);
        
        if (success) {
            event.setStatus(OutboxStatus.SENT);  // âœ… Success
        } else {
            event.setAttempts(event.getAttempts() + 1);
            if (event.getAttempts() >= 3) {
                event.setStatus(OutboxStatus.DLQ);  // âŒ Dead Letter Queue
            } else {
                event.setStatus(OutboxStatus.FAILED);  // âš ï¸ Will retry
            }
        }
        outboxEventRepository.save(event);
    }
}
```

**Pessimistic Lock:**
- Sá»­ dá»¥ng `@Lock(LockModeType.PESSIMISTIC_WRITE)` Ä‘á»ƒ trÃ¡nh nhiá»u instance xá»­ lÃ½ cÃ¹ng event
- Äáº£m báº£o **exactly-once processing**

### **BÆ°á»›c 3: Publish to Redis Stream**

`RedisStreamPublisherImpl` táº¡o message vá»›i **8 fields** vÃ  publish vÃ o Redis Stream:

```java
public boolean publishToStream(OutboxEvent event) {
    // 1. Build message fields
    Map<String, String> fields = new HashMap<>();
    fields.put("id", String.valueOf(event.getId()));
    fields.put("aggregateType", event.getAggregateType());
    fields.put("aggregateId", String.valueOf(event.getAggregateId()));
    fields.put("eventType", event.getEventType());
    fields.put("payload", event.getPayload());  // Full entity data as JSON
    fields.put("occurredAt", event.getOccurredAt().toString());
    fields.put("traceId", event.getTraceId().toString());
    fields.put("attempts", String.valueOf(event.getAttempts()));
    
    // 2. Create stream record
    var record = StreamRecords.newRecord()
            .ofStrings(fields)
            .withStreamKey("outbox:events");
    
    // 3. Publish to Redis Stream
    RecordId recordId = redisTemplate.opsForStream().add(record);
    
    return recordId != null;  // Success if recordId is not null
}
```

**Redis Stream State sau BÆ°á»›c 3:**
```
Stream: outbox:events
Message ID: 1705291200000-0
Fields:
  id: "123"
  aggregateType: "JOB"
  aggregateId: "456"
  eventType: "CREATED"
  payload: "{\"id\":456,\"title\":\"Software Engineer\",...}"
  occurredAt: "2024-01-15T10:30:00+07:00"
  traceId: "550e8400-e29b-41d4-a716-446655440000"
  attempts: "0"
```

### **BÆ°á»›c 4: Python Service Consumes**

Python service Ä‘á»c messages tá»« Redis Stream vÃ  sync vÃ o Milvus:

```python
import redis
import json

r = redis.Redis(host='localhost', port=6379, decode_responses=True)

# Create consumer group
try:
    r.xgroup_create("outbox:events", "milvus-sync", id="0", mkstream=True)
except:
    pass  # Group already exists

# Consume messages
while True:
    messages = r.xreadgroup(
        "milvus-sync",
        "worker-1",
        {"outbox:events": ">"},
        count=10,
        block=1000
    )
    
    for stream, msgs in messages:
        for msg_id, fields in msgs:
            # Parse event
            event_type = fields["eventType"]
            aggregate_type = fields["aggregateType"]
            payload = json.loads(fields["payload"])
            
            # Sync to Milvus
            if aggregate_type == "JOB":
                if event_type in ["CREATED", "UPDATED"]:
                    sync_job_to_milvus(payload)
                elif event_type == "DELETED":
                    delete_job_from_milvus(fields["aggregateId"])
            
            # Acknowledge message
            r.xack("outbox:events", "milvus-sync", msg_id)
```

---

## ğŸ§© CÃ¡c Components

### 1. **OutboxEventService** (Interface)
- Interface Ä‘á»ƒ save outbox events
- 2 methods:
  - `saveOutboxEvent(aggregateType, aggregateId, eventType, payload)` - Auto generate traceId
  - `saveOutboxEvent(aggregateType, aggregateId, eventType, payload, traceId)` - Custom traceId

### 2. **OutboxEventServiceImpl**
- Implementation cá»§a `OutboxEventService`
- LÆ°u event vÃ o database vá»›i status = `PENDING`
- Sá»­ dá»¥ng `@Transactional` Ä‘á»ƒ Ä‘áº£m báº£o atomic

### 3. **OutboxEventProcessor**
- **Scheduled component** cháº¡y má»—i 5 giÃ¢y
- Äá»c PENDING events tá»« database
- Publish events vÃ o Redis Stream
- Update status: `PENDING` â†’ `SENT` / `FAILED` â†’ `DLQ`

### 4. **RedisStreamPublisher**
- Interface Ä‘á»ƒ publish events vÃ o Redis Stream
- Method: `publishToStream(OutboxEvent event)`

### 5. **RedisStreamPublisherImpl**
- Implementation cá»§a `RedisStreamPublisher`
- Táº¡o stream record vá»›i 8 fields
- Publish vÃ o Redis Stream (`outbox:events`)

### 6. **OutboxEventRepository**
- JPA Repository vá»›i query methods
- `findPendingEvents(OutboxStatus.PENDING)` - Query vá»›i pessimistic lock

---

## ğŸ“Š Event States & Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PENDINGâ”‚ â† Created when event is saved
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ Processed by OutboxEventProcessor
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚                  â”‚
    â–¼                 â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SENT â”‚      â”‚ FAILED  â”‚      â”‚   DLQ   â”‚
â”‚       â”‚      â”‚         â”‚      â”‚         â”‚
â”‚âœ…Done â”‚      â”‚âš ï¸Retry  â”‚      â”‚âŒError  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ After 3 failed attempts
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DLQ
```

**Status Definitions:**
- **PENDING**: Event má»›i táº¡o, chÆ°a Ä‘Æ°á»£c publish
- **SENT**: Event Ä‘Ã£ Ä‘Æ°á»£c publish thÃ nh cÃ´ng vÃ o Redis Stream
- **FAILED**: Publish tháº¥t báº¡i, sáº½ retry (attempts < 3)
- **DLQ**: Dead Letter Queue - Publish tháº¥t báº¡i sau 3 láº§n thá»­

---

## ğŸ”’ Transactional Guarantees

### Atomicity
- Entity save vÃ  OutboxEvent save trong **cÃ¹ng transaction**
- Náº¿u má»™t trong hai tháº¥t báº¡i â†’ cáº£ hai Ä‘á»u rollback

### Consistency
- Outbox event chá»‰ Ä‘Æ°á»£c táº¡o khi entity Ä‘Æ°á»£c lÆ°u thÃ nh cÃ´ng
- KhÃ´ng cÃ³ orphan events

### Isolation
- Sá»­ dá»¥ng **Pessimistic Lock** khi query PENDING events
- Äáº£m báº£o khÃ´ng cÃ³ race condition giá»¯a cÃ¡c instances

### Durability
- Events Ä‘Æ°á»£c lÆ°u trong PostgreSQL (durable storage)
- KhÃ´ng bá»‹ máº¥t ngay cáº£ khi application crash

---

## ğŸš€ Retry Mechanism

### Automatic Retry
- Failed events Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u `FAILED`
- Processor sáº½ retry events cÃ³ status `FAILED` trong láº§n cháº¡y tiáº¿p theo
- Maximum 3 attempts

### Dead Letter Queue (DLQ)
- Sau 3 láº§n thá»­ tháº¥t báº¡i â†’ chuyá»ƒn sang `DLQ`
- DLQ events cáº§n Ä‘Æ°á»£c xá»­ lÃ½ manually hoáº·c alert

---

## ğŸ“ Example: Complete Flow

### Scenario: Create a new Job

**1. User creates job via API:**
```
POST /api/jobs
{
  "title": "Software Engineer",
  "company": "Acme Corp",
  ...
}
```

**2. JobServiceImpl.createJob():**
```java
@Transactional
public JobResponse createJob(...) {
    // Save job
    Job job = jobRepository.save(new Job(...));
    
    // Save outbox event
    JobResponse response = mapper.toResponse(job);
    String payload = objectMapper.writeValueAsString(response);
    outboxEventService.saveOutboxEvent("JOB", job.getId(), "CREATED", payload);
    
    return response;  // Transaction commits here
}
```

**3. Database state:**
```sql
-- jobs table
INSERT INTO jobs (id, title, ...) VALUES (456, 'Software Engineer', ...);

-- outbox_events table
INSERT INTO outbox_events 
  (id, aggregate_type, aggregate_id, event_type, payload, status, attempts)
VALUES 
  (123, 'JOB', 456, 'CREATED', '{"id":456,...}', 'PENDING', 0);
```

**4. OutboxEventProcessor (after 5 seconds):**
- Queries: `SELECT * FROM outbox_events WHERE status = 'PENDING'`
- Finds event id=123
- Publishes to Redis Stream
- Updates status to 'SENT'

**5. Redis Stream:**
```
Stream: outbox:events
Message: 1705291200000-0
  id: "123"
  aggregateType: "JOB"
  aggregateId: "456"
  eventType: "CREATED"
  payload: "{\"id\":456,\"title\":\"Software Engineer\",...}"
  ...
```

**6. Python Service:**
- Consumes message from stream
- Parses payload JSON
- Syncs job data to Milvus vector database
- Acknowledges message

---

## âš™ï¸ Configuration

### Application Properties
```properties
# Redis Stream key (default: outbox:events)
outbox.redis.stream.key=outbox:events

# Redis connection
spring.data.redis.host=localhost
spring.data.redis.port=6379
```

### Scheduler Configuration
- **Frequency**: Every 5 seconds (`fixedDelay = 5000`)
- **Initial Delay**: 10 seconds (`initialDelay = 10000`)
- **Retry Attempts**: Maximum 3 attempts

---

## ğŸ” Monitoring & Debugging

### Check Pending Events
```sql
SELECT * FROM outbox_events 
WHERE status = 'PENDING' 
ORDER BY occurred_at ASC;
```

### Check Failed Events
```sql
SELECT * FROM outbox_events 
WHERE status IN ('FAILED', 'DLQ') 
ORDER BY occurred_at DESC;
```

### Check Redis Stream
```bash
# Stream info
redis-cli XINFO STREAM outbox:events

# Read messages
redis-cli XREAD COUNT 10 STREAMS outbox:events 0

# Consumer groups
redis-cli XINFO GROUPS outbox:events
```

---

## âœ… Best Practices

1. **Always use @Transactional** when saving outbox events
2. **Handle exceptions gracefully** - don't let outbox failures break main flow
3. **Use meaningful event types** - CREATED, UPDATED, DELETED, PUBLISHED
4. **Include full entity data** in payload for downstream services
5. **Monitor DLQ** - Alert when events move to DLQ
6. **Test event publishing** - Verify events appear in Redis Stream
7. **Use consumer groups** in Python service for reliable consumption

---

## ğŸ¯ Benefits

âœ… **Reliability**: Events guaranteed to be saved before transaction commits
âœ… **Atomicity**: Entity and event save in same transaction
âœ… **Durability**: Events stored in PostgreSQL (no data loss)
âœ… **Retry Logic**: Automatic retry for failed publishes
âœ… **Scalability**: Can handle high throughput with background processing
âœ… **Decoupling**: Producer and consumer are decoupled via Redis Stream

---

## ğŸ› ï¸ Troubleshooting

### Events stuck in PENDING
- Check if `OutboxEventProcessor` is running
- Check scheduler is enabled: `@EnableScheduling`
- Check logs for errors

### Events in DLQ
- Check Redis connection
- Check Redis Stream is accessible
- Manual retry: Update status from DLQ to PENDING

### Missing events in Redis Stream
- Check `RedisStreamPublisher` logs
- Verify Redis connection
- Check stream key configuration

---

## ğŸ“š Summary

Outbox Pattern vá»›i Redis Stream Ä‘áº£m báº£o:
1. âœ… **Reliable event publishing** - Events Ä‘Æ°á»£c lÆ°u trong DB trÆ°á»›c
2. âœ… **Transactional consistency** - Entity vÃ  event trong cÃ¹ng transaction
3. âœ… **Background processing** - KhÃ´ng block main flow
4. âœ… **Automatic retry** - Retry failed publishes
5. âœ… **Scalable consumption** - Python service consume tá»« Redis Stream
6. âœ… **Milvus sync** - Python service sync data vÃ o Milvus vector database

